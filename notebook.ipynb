{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9300112,"sourceType":"datasetVersion","datasetId":5631016},{"sourceId":210556512,"sourceType":"kernelVersion"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":4.734316,"end_time":"2024-11-30T12:59:34.374568","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-30T12:59:29.640252","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"776a31b6-d92b-4746-b59c-5e43ed79e7b6","cell_type":"code","source":"!pip install transformers==4.46.3 \n!pip install accelerate==1.1.1 \n!pip install bitsandbytes==0.44.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T18:34:58.603333Z","iopub.execute_input":"2024-12-31T18:34:58.603743Z","iopub.status.idle":"2024-12-31T18:35:07.929774Z","shell.execute_reply.started":"2024-12-31T18:34:58.603710Z","shell.execute_reply":"2024-12-31T18:35:07.928709Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.10/dist-packages (4.46.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.3) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.3) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.3) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.3) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.3) (2024.8.30)\nRequirement already satisfied: accelerate==1.1.1 in /usr/local/lib/python3.10/dist-packages (1.1.1)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (0.24.7)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (0.4.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.1.1) (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.1) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.1) (2024.6.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.1) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.1) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.1.1) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.1.1) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==1.1.1) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==1.1.1) (1.3.0)\nRequirement already satisfied: bitsandbytes==0.44.1 in /usr/local/lib/python3.10/dist-packages (0.44.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.44.1) (2.4.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.44.1) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.44.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.44.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes==0.44.1) (1.3.0)\n","output_type":"stream"}],"execution_count":2},{"id":"bf50f431-e587-4c96-9652-d10cc951bad6","cell_type":"code","source":"#!pip install -U bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3cfa8375-6d47-40d1-b64b-7c65baead0f4","cell_type":"code","source":"%cd /kaggle/input/mistral-nemo-instruct-2407","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"20385709-d939-48ea-a604-5313bb20f9b5","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2fa1c857-919d-4cf0-8a7f-648e11e0b582","cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\nimport torch\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a28cc11c-72a7-4a23-9711-c831d36632e7","cell_type":"code","source":"quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"47a7b914-5362-4481-a1ba-b19d2ea13a93","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e5f1cb30-fb72-4172-a376-fc36ab7daf5e","cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\"./\", torch_dtype=torch.bfloat16,quantization_config=quantization_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d9e8a337-6e33-4695-b4b2-e5f55fbbba28","cell_type":"code","source":"model_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\ntokenizer = AutoTokenizer.from_pretrained(\"./\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"842147fe-c97e-4a3a-b449-a49d749a3971","cell_type":"code","source":"import re\nimport requests\nimport json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"063c10e4-c45e-44f4-86ed-dcbef867bea0","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6d38aaed-ed6d-41c3-a87d-bc0da26b04cb","cell_type":"code","source":"from functions_to_call import *","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a731f281-afd2-4172-86f3-783854523239","cell_type":"code","source":"%%time\nprompt=\"give me a satellite snapshot from my location 34.04155284331105, -4.996594567903626\"\n#prompt=\"who are you\"\nconversation = [{\"role\": \"user\", \"content\": prompt}]\ntools = [get_current_weather,get_closest_hospital,get_safest_routes,check_road_closures,find_emergency_supplies,haversine_distance]\n\n# format and tokenize the tool use prompt \ninputs = tokenizer.apply_chat_template(\n            conversation,\n            tools=tools,\n            add_generation_prompt=True,\n            return_dict=True,\n            return_tensors=\"pt\",\n)\n\ninputs.to(model.device)\noutputs = model.generate(**inputs, max_new_tokens=1000)\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"93b9fdb7-3e71-48a4-af2d-daa99e62904b","cell_type":"code","source":"tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):],skip_special_tokens=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ced134b5-7d67-44db-805d-572e5d9b00ef","cell_type":"code","source":"function_map = {\n    \"get_current_weather\": get_current_weather,\n    \"get_closest_hospital\":get_closest_hospital,\n    \"get_safest_routes\":get_safest_routes,\n    \"check_road_closures\":check_road_closures,\n    \"find_emergency_supplies\":find_emergency_supplies,\n    \"haversine_distance\":haversine_distance\n}\n\ndef exec_called_func(response,function_map):\n    match = re.search(r'\\[{\"name\": \"(.*?)\", \"arguments\": (.*?)\\}]', response)\n    if match:\n        function_call_part = match.group()  \n        \n        try:\n            function_call = json.loads(function_call_part)\n        except json.JSONDecodeError as e:\n            print(f\"Error decoding JSON: {e}\")\n            function_call = None\n        \n        if function_call:\n            function_name = function_call[0][\"name\"]\n            arguments = function_call[0][\"arguments\"]\n            \n    \n            if function_name in function_map:\n                try:\n                    result = function_map[function_name](**arguments)\n                    return result\n                except Exception as e:\n                    print(f\"Error executing function '{function_name}': {e}\")\n            else:\n                print(f\"Unknown function: {function_name}\")\n    else:\n        print(\"No function call found in the response.\")\n#exec_called_func(response,function_map)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3e678ba7-4167-4d00-821d-5cbd6ac14891","cell_type":"code","source":"disaster_info={\n    \"disaster_report\": {\n        \n        \"type\": \"earthquake\",\n        \"location\": {\n            \"latitude\": 34.0522,\n            \"longitude\": -118.2437,\n            \"city\": \"Los Angeles\",\n            \"region\": \"California\",\n            \"country\": \"United States\"\n        },\n        \"image_url\":\"https://images.axios.com/-0E5vD5wfUhUCvjCozznsl4ZJFw=/2023/09/11/1694467770528.jpg\",\n        \"timestamp\": \"2024-11-27T14:30:00Z\",\n        \"damage_levels\": {\n            \"infrastructure\": {\n                \"level\": \"severe\",\n                \"description\": \"Significant structural damage to buildings and critical infrastructure\",\n                \"percentage_affected\": 45.5\n            },\n            \"residential_areas\": {\n                \"level\": \"high\",\n                \"description\": \"Extensive damage to residential structures\",\n                \"buildings_destroyed\": 1200,\n                \"buildings_damaged\": 3500\n            },\n            \"transportation\": {\n                \"level\": \"moderate\",\n                \"description\": \"Road and bridge damage limiting mobility\",\n                \"roads_blocked\": 37,\n                \"bridges_compromised\": 12\n            }\n        },\n        \"impact_metrics\": {\n            \"casualties\": {\n                \"fatalities\": 87,\n                \"injured\": 350,\n                \"displaced\": 5600\n            },        \n\n    }\n}\n}\n\n\ndef create_system_prompt(disaster_info, user_location):\n    # Extract necessary information from disaster_info\n    disaster_type = disaster_info[\"disaster_report\"][\"type\"]\n    disaster_location = disaster_info[\"disaster_report\"][\"location\"]\n    disaster_lat = disaster_location[\"latitude\"]\n    disaster_lon = disaster_location[\"longitude\"]\n    city = disaster_location[\"city\"]\n    region = disaster_location[\"region\"]\n    country = disaster_location[\"country\"]\n    casualties = disaster_info[\"disaster_report\"][\"impact_metrics\"][\"casualties\"]\n    fatalities = casualties[\"fatalities\"]\n    injured = casualties[\"injured\"]\n    displaced = casualties[\"displaced\"]\n    disaster_img=disaster_info[\"disaster_report\"][\"image_url\"]\n    \n    # Ensure user_location is in the correct format\n    if isinstance(user_location, dict) and 'latitude' in user_location and 'longitude' in user_location:\n        user_lat = user_location['latitude']\n        user_lon = user_location['longitude']\n        user_loc_str = f\"User Location - {user_lat}, {user_lon}\"\n    elif isinstance(user_location, str):\n        user_loc_str = f\"User Location - {user_location}\"\n    else:\n        user_loc_str = \"User Location - Unknown\"\n    \n    # Construct the system prompt with both disaster and user locations\n    system_prompt = (\n        f\"You are a friendly and concise chatbot aiding in disaster response and GIS mapping, offering critical information, safety guidance, and spatial analysis for emergency operations. \"\n        f\"Here's the disaster report: \\n\"\n        f\"Disaster Type - {disaster_type}, \\n\"\n        f\"Disaster Location - {city}, {region}, {country} ({disaster_lat}, {disaster_lon}), \\n\"\n        f\"Casualties - {fatalities} fatalities, {injured} injured, {displaced} displaced, \\n\"\n        f\"user location:- {user_loc_str} \\n\"\n        f\"disaster image url: {disaster_img}\"\n        f\"if the user what image of the disaster give it to him in the following format [Disaster_Image](URL) eg. [Disaster_Image](https://images.axios.com/-0E5vD5wfUhUCvjCozznsl4ZJFw=/2023/09/11/1694467770528.jpg)\"\n    )\n    \n\n    return system_prompt\n\nuser_location = {'latitude': 37.7749, 'longitude': -122.4194}\nuser_location = \"San Francisco, CA\"\nsystem_prompt = create_system_prompt(disaster_info, user_location)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"16858024-0476-4156-985c-e5050ee93ee8","cell_type":"code","source":"system_prompt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"280e2f8b-982e-49fc-96fe-c504eca58fc9","cell_type":"code","source":"def format_response(text):\n    pattern = r'\\[Disaster_Image\\]\\((.*?)\\)'\n    url= re.findall(pattern, text[\"response\"])\n    if url:\n        text=text[\"response\"].replace(f\"[Disaster_Image]({url[0]})\",\"\")\n        url=url[0]\n    return {\"response\":text ,\"Image_url\": url if url else None}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2ed75839-d65c-4eac-b88d-c250420bbc90","cell_type":"code","source":"import json\nimport random\nimport string\nimport re\nfrom pydantic import BaseModel\n\n# Conversation memory management\nclass ConversationMemory:\n    def __init__(self):\n        self.memory = [\n            {\"role\": \"system\", \"content\": system_prompt}\n        ]\n\n    def add_message(self, role, content):\n        self.memory.append({\"role\": role, \"content\": content})\n        return self.memory\n\n    def get_memory(self):\n        return self.memory\n\n# Initialize conversation memory\nconversation_memory = ConversationMemory()\n\n# Pydantic model for request validation\nclass UserPrompt(BaseModel):\n    prompt: str\n\ndef format_response(text):\n    pattern = r'\\[Disaster_Image\\]\\((.*?)\\)'\n    url = re.findall(pattern, text[\"response\"])\n    if url:\n        text[\"response\"] = text[\"response\"].replace(f\"[Disaster_Image]({url[0]})\", \"\")\n        url = url[0]\n    return {\"response\": text[\"response\"], \"Image_url\": url if url else None}\n\ndef process_chat(user_input: UserPrompt):\n    try:\n        # Update conversation memory with user prompt\n        current_memory = conversation_memory.add_message(\"user\", user_input.prompt)\n        \n        # Prepare inputs for the model\n        inputs = tokenizer.apply_chat_template(\n            current_memory,\n            tools=tools,\n            do_sample=True,\n            top_p=0.9,\n            add_generation_prompt=True,\n            return_dict=True,\n            repetition_penalty=1.1,\n            return_tensors=\"pt\"\n        )\n        \n        # Move inputs to the correct device\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        # Generate response\n        outputs = model.generate(**inputs, max_new_tokens=128)\n        response_text = tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n\n        # Check if the response contains a function call\n        if re.search(r'\\[{\"name\": \"(.*?)\", \"arguments\": (.*?)\\}]', response_text):\n            # Step 3: Generate a unique tool call ID\n            tool_call_id = ''.join(random.choices(string.ascii_letters + string.digits, k=9))\n\n            # Step 4: Parse response in JSON format\n            try:\n                tool_call = json.loads(response_text)[0]\n            except:\n                json_part = re.search(r'\\[.*\\]', response_text, re.DOTALL).group(0)\n                tool_call = json.loads(json_part)[0]\n\n            # Step 5: Executing Functions and Obtaining Results\n            function_name = tool_call[\"name\"]\n            arguments = tool_call[\"arguments\"]\n            tool_output = function_map[function_name](**arguments)\n\n            # Append tool call and tool response to messages\n            messages = current_memory.copy()\n            messages.append({\"role\": \"assistant\", \"tool_calls\": [{\"type\": \"function\", \"id\": tool_call_id, \"function\": tool_call}]})\n            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call_id, \"name\": function_name, \"content\": str(tool_output)})\n\n            # Step 6: Generating the Final Answer Based on Function Output\n            final_inputs = tokenizer.apply_chat_template(\n                messages,\n                add_generation_prompt=True,\n                return_dict=True,\n                return_tensors=\"pt\"\n            )\n            final_inputs = {k: v.to(model.device) for k, v in final_inputs.items()}\n            final_outputs = model.generate(**final_inputs, max_new_tokens=128)\n            final_response = tokenizer.decode(final_outputs[0][len(final_inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n\n            # Update conversation memory with the final response\n            conversation_memory.add_message(\"assistant\", final_response)\n\n            return format_response({\n                \"response\": final_response,\n                \"memory_length\": len(conversation_memory.get_memory())\n            })\n        elif \"[Disaster_Image]\" in response_text:\n            temp_memory = [{\"role\": \"system\", \"content\": \"You are a friendly and concise chatbot.\"}]\n            temp_memory.append({\"role\": \"user\", \"content\": f\"Answer to message and give the following like it's the wanted image that answers the question {user_input.prompt}: {response_text}\"})\n            \n            # Prepare inputs for reformulation with the updated temporary memory\n            reformulation_inputs = tokenizer.apply_chat_template(\n                temp_memory,\n                tools=tools,\n                do_sample=True,\n                top_p=0.9,\n                add_generation_prompt=True,\n                return_dict=True,\n                repetition_penalty=1.1,\n                return_tensors=\"pt\"\n            )\n            \n            # Move inputs to the correct device\n            reformulation_inputs = {k: v.to(model.device) for k, v in reformulation_inputs.items()}\n            \n            # Generate user-friendly response\n            reformulation_outputs = model.generate(**reformulation_inputs, max_new_tokens=200)\n            reformulation_context = tokenizer.decode(reformulation_inputs['input_ids'][0], skip_special_tokens=True)\n            full_reformulation = tokenizer.decode(reformulation_outputs[0], skip_special_tokens=True)\n            response_text = full_reformulation[len(reformulation_context):].strip()\n            conversation_memory.add_message(\"assistant\", response_text)\n            \n            return format_response({\n                \"response\": response_text,\n                \"memory_length\": len(conversation_memory.get_memory())\n            })\n    \n        else:\n            # If no function call, just add the assistant's response to memory\n            conversation_memory.add_message(\"assistant\", response_text)\n\n            return format_response({\n                \"response\": response_text,\n                \"memory_length\": len(conversation_memory.get_memory())\n            })\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\ndef memory():\n    return {\"response\": conversation_memory.get_memory()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"36bd8107-2f88-4ca3-8bda-9d87d6a9a787","cell_type":"code","source":"user_input = UserPrompt(prompt=\"give me disaster image\")\nresponse = process_chat(user_input)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5e137a30-41c3-4586-a8ab-d9be885bfbc0","cell_type":"code","source":"response","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"307c681b-4f2a-4d9d-8315-ae81b51bb8ba","cell_type":"markdown","source":"# Sitting API","metadata":{}},{"id":"62f37d14-8692-453a-bc7b-5db0b8a145a3","cell_type":"code","source":"!pip install uvicorn fastapi ngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d3cd18b6-2812-402c-b108-fa7b3fa86045","cell_type":"code","source":"import ngrok\nimport time\nimport asyncio\nimport nest_asyncio\nimport uvicorn\nimport ngrok\nimport time\nimport asyncio\nimport nest_asyncio\nimport uvicorn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d1380a46-9044-4106-9310-44f6e33d4514","cell_type":"code","source":"from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport torch\n\napp = FastAPI(title=\"Conversational AI Chatbot\")\n\n# Conversation memory management\nclass ConversationMemory:\n    def __init__(self, max_memory=10):\n        self.memory = [\n            {\"role\": \"system\", \"content\": system_prompt}\n        ]\n\n        self.max_memory = max_memory\n\n    def add_message(self, role, content):\n        # Add new message to memory\n        self.memory.append({\"role\": role, \"content\": content})\n        \n        # Trim memory if it exceeds max length\n        if len(self.memory) > self.max_memory:\n            self.memory = self.memory[-self.max_memory:]\n        \n        return self.memory\n\n    def get_memory(self):\n        return self.memory\n\n# Initialize conversation memory\nconversation_memory = ConversationMemory()\n\n# Pydantic model for request validation\nclass UserPrompt(BaseModel):\n    prompt: str\n\n\n@app.post(\"/chat\")\ndef process_chat(user_input: UserPrompt):\n    try:\n        # Update conversation memory with user prompt\n        current_memory = conversation_memory.add_message(\"user\", user_input.prompt)\n        \n        # Prepare inputs for the model\n        inputs = tokenizer.apply_chat_template(\n            current_memory,\n            tools=tools,\n            do_sample=True,\n            top_p=0.9,\n            add_generation_prompt=True,\n            return_dict=True,\n            repetition_penalty=1.1,\n            return_tensors=\"pt\"\n        )\n        \n\n        # Move inputs to the correct device\n        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n        \n        # Generate response\n        outputs = model.generate(**inputs, max_new_tokens=1000)\n\n        input_context = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        response_text = full_response[len(input_context):].strip()\n\n        match = re.search(r'\\[{\"name\": \"(.*?)\", \"arguments\": (.*?)\\}]', response_text)\n        if match:\n            # Execute the function (which will always return a dictionary)\n            function_result = exec_called_func(response_text, function_map)\n            \n            # Convert dictionary to a string description\n            function_result_str = \" \".join([f\"{k}: {v}\" for k, v in function_result.items()])\n            \n            \n            # Create a copy of the current conversation memory\n            temp_memory = [{\"role\": \"system\", \"content\": \"You are a friendly and concise chatbot.\"}]\n            temp_memory.append({\"role\": \"user\", \"content\": f\"Here are the details: {function_result_str}.give conversational response about this information.that answer the question {user_input.prompt}\"})\n            \n            # Prepare inputs for reformulation with the updated temporary memory\n            reformulation_inputs = tokenizer.apply_chat_template(\n            temp_memory,\n            tools=tools,\n            do_sample=True,\n            top_p=0.9,\n            add_generation_prompt=True,\n            return_dict=True,\n            repetition_penalty=1.1,\n            return_tensors=\"pt\"\n            )\n            \n            # Move inputs to the correct device\n            reformulation_inputs = {k: v.to(model.device) for k, v in reformulation_inputs.items()}\n            \n            # Generate user-friendly response\n            reformulation_outputs = model.generate(**reformulation_inputs, max_new_tokens=200)\n            reformulation_context = tokenizer.decode(reformulation_inputs['input_ids'][0], skip_special_tokens=True)\n            full_reformulation = tokenizer.decode(reformulation_outputs[0], skip_special_tokens=True)\n            response_text = full_reformulation[len(reformulation_context):].strip()\n            \n            # Update memory with the final reformulated response\n            conversation_memory.add_message(\"assistant\", response_text)\n        elif \"[Disaster_Image]\" in response_text:\n            temp_memory = [{\"role\": \"system\", \"content\": \"You are a friendly and concise chatbot.\"}]\n            temp_memory.append({\"role\": \"user\", \"content\": f\"Answer to message and  give the following like it's the wanted image that answers the question {user_input.prompt}: {response_text}\"})\n            \n            # Prepare inputs for reformulation with the updated temporary memory\n            reformulation_inputs = tokenizer.apply_chat_template(\n            temp_memory,\n            tools=tools,\n            do_sample=True,\n            top_p=0.9,\n            add_generation_prompt=True,\n            return_dict=True,\n            repetition_penalty=1.1,\n            return_tensors=\"pt\"\n            )\n            \n            # Move inputs to the correct device\n            reformulation_inputs = {k: v.to(model.device) for k, v in reformulation_inputs.items()}\n            \n            # Generate user-friendly response\n            reformulation_outputs = model.generate(**reformulation_inputs, max_new_tokens=200)\n            reformulation_context = tokenizer.decode(reformulation_inputs['input_ids'][0], skip_special_tokens=True)\n            full_reformulation = tokenizer.decode(reformulation_outputs[0], skip_special_tokens=True)\n            response_text = full_reformulation[len(reformulation_context):].strip()\n            conversation_memory.add_message(\"assistant\", response_text)\n        else:\n            # If no function call, just add the assistant's response to memory\n            conversation_memory.add_message(\"assistant\", response_text)\n        \n        \n        return format_response({\n            \"response\":response_text,\n            \"memory_length\": len(conversation_memory.get_memory())\n        })\n    \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/memory\")\ndef memory():\n    return {\"response\":conversation_memory.get_memory()}\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"03b0e6da-b9d8-4969-bf11-3cbe84d2f069","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"419aede0-338e-46f6-86a7-b209a5ed1eb0","cell_type":"code","source":"from fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Replace \"\" with a specific domain, e.g., [\"http://localhost:5173\"]\n    allow_credentials=True,\n    allow_methods=[\"*\"],  # Allow all HTTP methods\n    allow_headers=[\"*\"],  # Allow all headers\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"81276c0e-e9bb-4899-a990-35aab7daa3a9","cell_type":"code","source":"#ngrok.kill()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"814c1996-0b6e-49a3-a945-eb84773dd821","cell_type":"code","source":"#!pip install ngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8781e9ea-8b12-41a7-9524-aad806757c5d","cell_type":"code","source":"\nlistener = ngrok.forward(8000,authtoken=\"2AJIi96LQAsJkU7nvb3xDCYQB4E_89fGp9rnUthkzsX7C4JKi\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3281e202-eece-4958-9c57-c2d20a35a989","cell_type":"code","source":"\n\ntunnel = await listener\nprint(f\"Ingress established at {tunnel.url()}\")\nnest_asyncio.apply()\nuvicorn.run(app, port=8000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f6de78d9-7963-45b0-8fbd-ed2d66346ec3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}